{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import os,sys\n",
    "# from PIL import Image\n",
    "\n",
    "from helpers import *\n",
    "from helpers_NN import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pip\n",
    "\n",
    "try: \n",
    "    import cv2\n",
    "except: \n",
    "    pip.main(['install', 'opencv-python'])\n",
    "    import cv2 \n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except: \n",
    "    pip.main(['install', 'tensorflow'])\n",
    "    import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 20\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/images/satImage_001.png\n",
      "Loading training/images/satImage_002.png\n",
      "Loading training/images/satImage_003.png\n",
      "Loading training/images/satImage_004.png\n",
      "Loading training/images/satImage_005.png\n",
      "Loading training/images/satImage_006.png\n",
      "Loading training/images/satImage_007.png\n",
      "Loading training/images/satImage_008.png\n",
      "Loading training/images/satImage_009.png\n",
      "Loading training/images/satImage_010.png\n",
      "Loading training/images/satImage_011.png\n",
      "Loading training/images/satImage_012.png\n",
      "Loading training/images/satImage_013.png\n",
      "Loading training/images/satImage_014.png\n",
      "Loading training/images/satImage_015.png\n",
      "Loading training/images/satImage_016.png\n",
      "Loading training/images/satImage_017.png\n",
      "Loading training/images/satImage_018.png\n",
      "Loading training/images/satImage_019.png\n",
      "Loading training/images/satImage_020.png\n",
      "Loading training/groundtruth/satImage_001.png\n",
      "Loading training/groundtruth/satImage_002.png\n",
      "Loading training/groundtruth/satImage_003.png\n",
      "Loading training/groundtruth/satImage_004.png\n",
      "Loading training/groundtruth/satImage_005.png\n",
      "Loading training/groundtruth/satImage_006.png\n",
      "Loading training/groundtruth/satImage_007.png\n",
      "Loading training/groundtruth/satImage_008.png\n",
      "Loading training/groundtruth/satImage_009.png\n",
      "Loading training/groundtruth/satImage_010.png\n",
      "Loading training/groundtruth/satImage_011.png\n",
      "Loading training/groundtruth/satImage_012.png\n",
      "Loading training/groundtruth/satImage_013.png\n",
      "Loading training/groundtruth/satImage_014.png\n",
      "Loading training/groundtruth/satImage_015.png\n",
      "Loading training/groundtruth/satImage_016.png\n",
      "Loading training/groundtruth/satImage_017.png\n",
      "Loading training/groundtruth/satImage_018.png\n",
      "Loading training/groundtruth/satImage_019.png\n",
      "Loading training/groundtruth/satImage_020.png\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, TRAINING_SIZE)\n",
    "train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 10)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points per class: c0 = 9450 c1 = 3050\n"
     ]
    }
   ],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "c0, c1 = 0, 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print ('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing training data...\n",
      "6100\n",
      "(12500, 10)\n",
      "Number of data points per class: c0 = 3050 c1 = 3050\n"
     ]
    }
   ],
   "source": [
    "print ('Balancing training data...')\n",
    "min_c = min(c0, c1)\n",
    "idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "print (len(new_indices))\n",
    "print (train_data.shape)\n",
    "train_data = train_data[new_indices,:]\n",
    "train_labels = train_labels[new_indices]\n",
    "\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "c0, c1 = 0, 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print ('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network parameters\n",
    "nb_hidden_nodes_1 = 100\n",
    "# nb_hidden_nodes_2 = \n",
    "num_patch = train_size\n",
    "num_features = train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 10)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patch * num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and bias for the first layer\n",
    "W_fc1 = weight_variable([num_features, nb_hidden_nodes_1], \"W_fc1\")\n",
    "b_fc1 = bias_variable([nb_hidden_nodes_1],\"b_fc1\")\n",
    "\n",
    "# Weights and bias for the second layer\n",
    "W_fc2 = weight_variable([nb_hidden_nodes_1, NUM_LABELS], \"W_fc2\")\n",
    "b_fc2 = bias_variable([NUM_LABELS],\"b_fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.\n",
    "def model(data):\n",
    "\n",
    "    # First layer\n",
    "    with tf.name_scope('FullyConnected1'):\n",
    "        h_fc1 = tf.matmul(data, W_fc1) + b_fc1\n",
    "        h_relu1 = tf.nn.relu(h_fc1)\n",
    "    \n",
    "    # Second Layre\n",
    "    with tf.name_scope('FullyConnected2'):\n",
    "        h_fc2 = tf.matmul(h_relu1, W_fc2) + b_fc2\n",
    "        valren = h_fc2\n",
    "        \n",
    "    return valren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10), Dimension(100)])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, tf_train_labels, lambda_reg = 1e-5):\n",
    "    regularization = True\n",
    "    if not regularization:\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = tf_train_labels))\n",
    "    else:\n",
    "        norms = tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(W_fc2)\n",
    "        print(norms)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels =  tf_train_labels) + lambda_reg*norms)\n",
    "         \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_12:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_6:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(train_data)\n",
    "loss = compute_loss(logits, train_labels)\n",
    "tf.summary.scalar('loss', loss)\n",
    "    \n",
    "tf.Print(loss, [loss], \"This is loss  \")\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_dataset, train_labels, valid_dataset, valid_labels, test_dataset, test_labels, saveModelPath):    \n",
    "    # Construct the graph\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        with tf.name_scope('Inputs_management'):\n",
    "            tf_train_dataset = tf.placeholder(tf.float32, shape=(BATCH_SIZE, num_patch * num_features), name='tf_train_dataset')\n",
    "            tf_train_labels = tf.placeholder(tf.int32, shape=(BATCH_SIZE, NUM_LABELS), name='tf_train_labels')\n",
    "\n",
    "            keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "            tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "            tf_data = tf.placeholder(tf.float32, shape=(1, num_patch * num_features), name=\"input\")\n",
    "\n",
    "        with tf.name_scope('Bias_and_weights_management'):\n",
    "            weightsDict = bias_weights_creation(nb_hidden_nodes_1 = nb_hidden_nodes_1, nb_hidden_nodes_2 = nb_hidden_nodes_2)    \n",
    "\n",
    "        # Training computation.\n",
    "        with tf.name_scope('Training_computations'):\n",
    "            logits, weightsDict = model(tf_train_dataset, weightsDict)\n",
    "\n",
    "        with tf.name_scope('Loss_computation'):\n",
    "            loss = loss(logits, tf_train_labels, lambda_reg, weightsDict)\n",
    "\n",
    "        print(\"Loss computation\")\n",
    "        with tf.name_scope('Optimization'):\n",
    "            # Optimizer.\n",
    "            optimizer = tf.train.GradientDescentOptimizer(classifier.learning_rate).minimize(loss)\n",
    "            # optimizer = tf.train.AdagradOptimizer(classifier.learning_rate).minimize(loss)\n",
    "\n",
    "        tf.summary.scalar(\"Loss\", loss)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver(weightsDict)\n",
    "\n",
    "\n",
    "        with tf.name_scope('Predictions'):\n",
    "            # Predictions for the training, validation, and test data.\n",
    "            train_prediction = tf.nn.softmax(logits)\n",
    "            valid_prediction = tf.nn.softmax(classifier.model(tf_valid_dataset, weightsDict)[0], name=\"valid_prediction\")\n",
    "\n",
    "            data_pred = tf.nn.softmax(model(tf_data, weightsDict)[0], name=\"output\")\n",
    "            test_prediction = tf.nn.softmax(model(tf_test_dataset, weightsDict)[0])\n",
    "\n",
    "\n",
    "        # -------------------------- #\n",
    "        #       Let's run it         #\n",
    "        # -------------------------- #\n",
    "        # \n",
    "        with tf.Session(graph=graph) as session:\n",
    "            tf.global_variables_initializer().run()\n",
    "            print(\"Initialized\")\n",
    "\n",
    "            # create log writer object\n",
    "            writer = tf.summary.FileWriter('./train', graph=graph)\n",
    "\n",
    "            for epoch in range(0, classifier.num_epochs):\n",
    "                for step in range(classifier.num_steps):\n",
    "                    # Pick an offset within the training data, which has been randomized.\n",
    "                    # Note: we could use better randomization across epochs.\n",
    "                    offset = (step * BATCH_SIZE) % (train_labels.shape[0] - BATCH_SIZE)\n",
    "                    # Generate a minibatch.\n",
    "                    batch_data = train_dataset[offset:(offset + BATCH_SIZE), :]\n",
    "                    batch_labels = train_labels[offset:(offset + BATCH_SIZE), :]\n",
    "                    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "                    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "                    # and the value is the numpy array to feed to it.\n",
    "                    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob:0.7}\n",
    "                    _, l, predictions, summary = session.run([optimizer, loss, train_prediction, summary_op], feed_dict=feed_dict)\n",
    "                    # _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "                    # write log\n",
    "                    batch_count = 20\n",
    "                    writer.add_summary(summary, epoch * batch_count + step)\n",
    "\n",
    "\n",
    "                    if (step % 500 == 0):\n",
    "                        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                        print(\"Minibatch accuracy: %.1f%%\" % classifier.accuracy(predictions, batch_labels)[0])\n",
    "                        print(\"Validation accuracy: %.1f%%\" % classifier.accuracy(valid_prediction.eval(feed_dict = {keep_prob:1.0}), valid_labels)[0])\n",
    "\n",
    "            # finalaccuracy, mat_confusion, PPV, TPR = classifier.accuracy(test_prediction.eval(feed_dict={keep_prob:1.0}), test_labels)\n",
    "            finalaccuracy, mat_confusion = classifier.accuracy(test_prediction.eval(feed_dict={keep_prob:1.0}), test_labels)\n",
    "            # finalaccuracy, mat_confusion = classifier.accuracy(valid_prediction.eval(feed_dict={keep_prob:1.0}), valid_labels)\n",
    "            print(\"Test accuracy: %.1f%%\" % finalaccuracy)\n",
    "            print(\"\\n\\nConfusion matrix :\\n\" + str(mat_confusion))\n",
    "            # print \"\\n PPV : \" + str(PPV)\n",
    "            # print \"\\n TPR : \" + str(TPR)\n",
    "\n",
    "            save_path = saver.save(session, saveModelPath, write_meta_graph=True)\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    return finalaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 satellite + ground truth images\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "\n",
    "files = os.listdir(image_dir)\n",
    "\n",
    "n = len(files)\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "\n",
    "print(\"Loading \" + str(n) + \" satellite + ground truth images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = get_rotated_images(imgs,True)\n",
    "# gt_imgs = get_rotated_images(gt_imgs,False)\n",
    "\n",
    "# print(\"After rotation: \" + str(len(imgs)) + \" satellite + ground truth images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract patches from input images\n",
    "patch_size = 16 # each patch is 16*16 pixels\n",
    "\n",
    "img_patches = [img_crop_train(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [img_crop_train(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "# gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "\n",
    "# Linearize list of patches\n",
    "# img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "# gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X[i] : (10,)\n",
      "Computed 62500 features\n",
      "Feature dimension = 11\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "X = np.asarray([ extract_features(img_patches[i]) for i in range(len(img_patches))])\n",
    "\n",
    "print(\"shape X[i] : {}\".format(X[0].shape))\n",
    "\n",
    "# Features augmentation \n",
    "X = features_augmentation(X)\n",
    "\n",
    "# X = normalize(X)\n",
    "\n",
    "# Print feature statistics\n",
    "print('Computed ' + str(X.shape[0]) + ' features')\n",
    "print('Feature dimension = ' + str(X.shape[1]))\n",
    "# print('Number of classes = ' + str(np.max(Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    \"\"\" \n",
    "    input:  predictions - prediction array\n",
    "            labels      - real labels array\n",
    "    output: acc         - Accuracy: percentage of elements of predictions and labels that are the same\n",
    "            PPV         - Positive Predictive Value, Precision\n",
    "            TPR         - True Positive Rate, Sensitivity\n",
    "    \"\"\"\n",
    "    \n",
    "    conf_mat = confusion_matrix(labels, predictions)\n",
    "\n",
    "    TN = conf_mat[0,0]\n",
    "    FP = conf_mat[0,1]\n",
    "    FN = conf_mat[1,0]\n",
    "    TP = conf_mat[1,1]\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    PPV = TP / (TP + FP)\n",
    "    \n",
    "    meanFscore = 2 * PPV * TPR / (PPV + TPR)\n",
    "    F1 = 0\n",
    "    \n",
    "    acc = (TP + TN) / np.sum(conf_mat)\n",
    "    \n",
    "#     print(\"\\nTPR = Sensitivity = {}\".format(TPR))\n",
    "#     print(\"PPV = Precision = {}\".format(PPV))\n",
    "#     print(\"Mean F Score = {}\".format(meanFscore))\n",
    "#     print(\"F1 overall = {}\".format(F1))\n",
    "    \n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\prisgdd\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from plots import cross_validation_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10)\n",
    "kf.get_n_splits(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 10000.0\n",
      "Foreground threshold = 0.92\n",
      "\n",
      "1-th CV\n"
     ]
    }
   ],
   "source": [
    "# Compute features for each image patch\n",
    "# percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "foreground_threshold = np.arange(0.92, 0.921, 0.01) \n",
    "Cs = np.arange(1e4, 1e4 + 1, 10000) \n",
    "acc_threshold =[]\n",
    "\n",
    "accuracy_train_C = []\n",
    "f1_score_train_C = []\n",
    "\n",
    "accuracy_test_C = []\n",
    "f1_score_test_C = []\n",
    "\n",
    "for C in Cs:\n",
    "    print(\"C = {}\".format(C))\n",
    "    for threshold in foreground_threshold:\n",
    "        print(\"Foreground threshold = {}\".format(threshold))\n",
    "        def value_to_class(v):\n",
    "            df = np.sum(v)\n",
    "            if df > threshold:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])\n",
    "\n",
    "\n",
    "        accuracy_train_CV = []\n",
    "        accuracy_test_CV = []\n",
    "        \n",
    "        f1_score_train_CV = []\n",
    "        f1_score_test_CV = []\n",
    "        \n",
    "        for ind, [train_index, test_index] in enumerate(kf.split(imgs)):\n",
    "\n",
    "            ######## Split dataset ########\n",
    "            print(\"\\n{}-th CV\".format(ind+1))\n",
    "            \n",
    "            X_train = [imgs[ind] for ind in train_index]\n",
    "            X_test = [imgs[ind] for ind in test_index]\n",
    "            \n",
    "            y_train = [gt_imgs[ind] for ind in train_index]\n",
    "            y_test = [gt_imgs[ind] for ind in test_index]\n",
    "            \n",
    "#             # print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "#             X_train, X_test = X[train_index], X[test_index]\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            X_train = [img_crop_train(X_train[i], patch_size, patch_size) for i in range(len(train_index))]\n",
    "            y_train = [img_crop_train(y_train[i], patch_size, patch_size) for i in range(len(train_index))]\n",
    "            X_test = [img_crop(X_test[i], patch_size, patch_size) for i in range(len(test_index))]\n",
    "            y_test = [img_crop(y_test[i], patch_size, patch_size) for i in range(len(test_index))]\n",
    "    \n",
    "            X_train = np.asarray([X_train[i][j] for i in range(len(X_train)) for j in range(len(X_train[i]))])\n",
    "            X_test = np.asarray([X_test[i][j] for i in range(len(X_test)) for j in range(len(X_test[i]))])\n",
    "            y_train = np.asarray([y_train[i][j] for i in range(len(y_train)) for j in range(len(y_train[i]))])\n",
    "            y_test = np.asarray([y_test[i][j] for i in range(len(y_test)) for j in range(len(y_test[i]))])\n",
    "        \n",
    "            y_train = np.asarray([value_to_class(np.mean(y_train[i])) for i in range(y_train.shape[0])])\n",
    "            y_test = np.asarray([value_to_class(np.mean(y_test[i])) for i in range(y_test.shape[0])])\n",
    "            \n",
    "            X_train = np.asarray([ extract_features(X_train[i]) for i in range(len(X_train))])\n",
    "            X_train = features_augmentation(X_train)\n",
    "            \n",
    "            X_test = np.asarray([ extract_features(X_test[i]) for i in range(len(X_test))])\n",
    "            X_test = features_augmentation(X_test)\n",
    "            \n",
    "            \n",
    "            \n",
    "            ######## Run logistic regression ########\n",
    "            print(\"Logistic Regression // Logistic Regression + Postprocessing\")\n",
    "            logreg = linear_model.LogisticRegression(C=C, class_weight=\"balanced\")\n",
    "            logreg.fit(X_train, y_train)\n",
    "            z_train = logreg.predict(X_train)\n",
    "            z_test = logreg.predict(X_test)\n",
    "\n",
    "            f1_score_train = f1_score(y_train, z_train, average='macro')\n",
    "            accuracy_score_train = accuracy_score(y_train, z_train)\n",
    "            \n",
    "            f1_score_test = f1_score(y_test, z_test, average='macro')\n",
    "            accuracy_score_test = accuracy_score(y_test, z_test)\n",
    "\n",
    "            ######## Postprocessing ########\n",
    "            # Reshape prediction\n",
    "            z_reshaped = []\n",
    "\n",
    "            num_patch_total = len(z_test)\n",
    "            num_patch_by_img = num_patch_total // kf.get_n_splits(imgs)\n",
    "\n",
    "            for i in range(0, num_patch_total, num_patch_by_img):\n",
    "                z_crt = z_test[i : i + num_patch_by_img]\n",
    "                z_reshaped.append(np.reshape(z_crt, [400 // 16, 400 // 16]))\n",
    "\n",
    "\n",
    "            # Run post process \n",
    "            for ind, label_img in enumerate(z_reshaped):\n",
    "                label_img = postprocess(label_img)\n",
    "                z_reshaped[ind] = np.reshape(label_img, [z_crt.shape[0]])\n",
    "\n",
    "            # Convert list as array\n",
    "            z_test_pp = np.concatenate( z_reshaped , axis = 0 )\n",
    "\n",
    "            f1_score_test_pp = f1_score(y_test, z_test_pp, average='macro')\n",
    "            accuracy_score_test_pp = accuracy_score(y_test, z_test_pp)\n",
    "#             print(\" - - - F1 score test :: LogReg = {} ::: LogReg + PP = {}\".format(f1_score_test, f1_score_test_pp))\n",
    "#             print(\" - - - Accuracy score test :: LogReg {} ::: LogReg + PP {}\".format(accuracy_score_test, accuracy_score_test_pp))\n",
    "\n",
    "            \n",
    "            f1_score_train_CV.append(f1_score_train)\n",
    "            accuracy_train_CV.append(accuracy_score_train)\n",
    "            \n",
    "            f1_score_test_CV.append(f1_score_test_pp)\n",
    "            accuracy_test_CV.append(accuracy_score_test_pp)\n",
    "    \n",
    "    print(\"Average test accuracy: {}\".format(np.mean(accuracy_test_CV)))\n",
    "    print(\"Variance test accuracy: {}\".format(np.std(accuracy_test_CV)))\n",
    "    print(\"Min test accuracy: {}\".format(np.min(accuracy_test_CV)))\n",
    "    print(\"Max test accuracy: {}\\n\".format(np.max(accuracy_test_CV)))   \n",
    "    \n",
    "    accuracy_train_C.append(np.mean(accuracy_train_CV))\n",
    "    f1_score_train_C.append(np.mean(f1_score_train_CV))\n",
    "    \n",
    "    accuracy_test_C.append(np.mean(accuracy_test_CV))\n",
    "    f1_score_test_C.append(np.mean(f1_score_test_CV))\n",
    "        \n",
    "        \n",
    "# cross_validation_visualization(Cs, f1_score_train_C, f1_score_test_C)\n",
    "#     # we create an instance of the classifier and fit the data\n",
    "#     logreg = linear_model.LogisticRegression(C=1e5, class_weight=\"balanced\")\n",
    "#     logreg.fit(X, Y)\n",
    "    \n",
    "#     # Predict on the training set\n",
    "#     Z = logreg.predict(X)\n",
    "    \n",
    "#     acc = accuracy(labels = Y, predictions = Z)\n",
    "#     acc_threshold.append(acc)\n",
    "#     print(\"Foreground threshold = {}\".format(threshold))\n",
    "#     print(\"Accuracy post Logistic Regression: {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data to evaluate\n",
    "root_testdir = \"test_set_images\"\n",
    "test_names = os.listdir(root_testdir)\n",
    "\n",
    "num_test = len(test_names)\n",
    "\n",
    "imgs_test = [load_image(os.path.join(root_testdir, test_names[i], test_names[i]) + \".png\") for i in range(num_test)]\n",
    "\n",
    "img_patches_test = [img_crop(imgs_test[i], patch_size, patch_size) for i in range(num_test)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches_test = np.asarray([img_patches_test[i][j] for i in range(len(img_patches_test)) for j in range(len(img_patches_test[i]))])\n",
    "\n",
    "\n",
    "X_test = np.asarray([ extract_features(img_patches_test[i]) for i in range(len(img_patches_test))])\n",
    "X_test = features_augmentation(X_test)\n",
    "\n",
    "# X_test = normalize(X_test)\n",
    "\n",
    "# Run prediction\n",
    "Z_test = logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Postprocessing \"\"\"\n",
    "\n",
    "# Reshape prediction\n",
    "Z_reshaped = []\n",
    "\n",
    "num_patch_total = len(Z_test)\n",
    "num_patch_by_img = num_patch_total // num_test\n",
    "\n",
    "for i in range(0, num_patch_total, num_patch_by_img):\n",
    "    Z_crt = Z_test[i : i + num_patch_by_img]\n",
    "    Z_reshaped.append(np.reshape(Z_crt, [608 // 16, 608 // 16]))\n",
    "\n",
    "    \n",
    "# Run post process \n",
    "for ind, label_img in enumerate(Z_reshaped):\n",
    "    label_img = postprocess(label_img)\n",
    "    Z_reshaped[ind] = np.reshape(label_img, [Z_crt.shape[0]])\n",
    "    \n",
    "# Convert list as array\n",
    "result = np.concatenate( Z_reshaped , axis = 0 )\n",
    "\n",
    "# Save prediction\n",
    "create_submission(result, \"submission_postprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "patch_size = 16\n",
    "\n",
    "# Run prediction on the img_idx-th image\n",
    "img_idx = random.randint(0,n-1)\n",
    "img_idx = 1\n",
    "\n",
    "patch_size = 16\n",
    "Xi = extract_img_features(image_dir + files[img_idx])\n",
    "Xi = features_augmentation(Xi)\n",
    "Zi = logreg.predict(Xi)\n",
    "\n",
    "# Display prediction as an image\n",
    "w = gt_imgs[img_idx].shape[0]\n",
    "h = gt_imgs[img_idx].shape[1]\n",
    "\n",
    "predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zi_reshaped = np.reshape(Zi, [400 // 16, 400 // 16])\n",
    "postprocess_img = postprocess(Zi_reshaped)\n",
    "postprocess_img = np.reshape(postprocess_img, [Zi.shape[0]])\n",
    "postprocess_img = label_to_img(w, h, patch_size, patch_size, postprocess_img)\n",
    "    \n",
    "fig1 = plt.figure(figsize=(10, 10)) \n",
    "new_img = make_img_overlay(imgs[img_idx], postprocess_img)\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zi_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
